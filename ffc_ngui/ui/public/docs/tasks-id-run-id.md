### **Summary**

Use this page to visualize and access logging parameters, code versions, metrics, artifacts, and output files of your 
training code. A run corresponds to one execution of the training code.


### **View**

- Performance Management Toolbar: Use the Page toolbar with the "Refresh" button.

- Summary Cards: Get an overview of the run status, duration, and expenses.

- Overview: Monitor detailed information about the run, including metrics, dataset, code version, and hyperparameters.

- Charts: View training code execution data in a graphical format. Zoom in and out using the Timerange or the "SELECT 
  STAGE/MILESTONE" button. Hover over a point on the chart to see the exact value of the displayed parameter.

- Artifacts: Access a list with detailed information about the artifacts of the run.

- Executors: Check which executor was used to execute the training code. 

### **Actions**

- Create and Share Charts: Add a new chart to the dashboard by clicking the "Add Chart" button and selecting the 
  parameters you want to display (e.g., metrics, CPU, memory, etc.). After setting up all the necessary charts, save the 
  current dashboard view and share it with colleagues by clicking the "Save Dashboard" button.

### **Tips**

- Experiment Tracking: Runs allow you to log and track different parameters associated with your machine learning 
  experiments. This helps in keeping a detailed record of what was done during each experiment.

- Communication: Visualizations are effective tools for communicating results to stakeholders who may not be familiar 
  with the technical details of machine learning. They provide a straightforward way to present complex information.